{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh2IiRMkIr7h"
      },
      "source": [
        "# Task 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data extraction and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text limited to ~20k words (105021 characters)\n",
            "New word count: 19643\n",
            "Number of sequences: 20985\n",
            "Vectorizing sequences...\n",
            "Vectorizing sequence 0/20985\n",
            "Vectorizing sequence 1000/20985\n",
            "Vectorizing sequence 2000/20985\n",
            "Vectorizing sequence 3000/20985\n",
            "Vectorizing sequence 4000/20985\n",
            "Vectorizing sequence 5000/20985\n",
            "Vectorizing sequence 6000/20985\n",
            "Vectorizing sequence 7000/20985\n",
            "Vectorizing sequence 8000/20985\n",
            "Vectorizing sequence 9000/20985\n",
            "Vectorizing sequence 10000/20985\n",
            "Vectorizing sequence 11000/20985\n",
            "Vectorizing sequence 12000/20985\n",
            "Vectorizing sequence 13000/20985\n",
            "Vectorizing sequence 14000/20985\n",
            "Vectorizing sequence 15000/20985\n",
            "Vectorizing sequence 16000/20985\n",
            "Vectorizing sequence 17000/20985\n",
            "Vectorizing sequence 18000/20985\n",
            "Vectorizing sequence 19000/20985\n",
            "Vectorizing sequence 20000/20985\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "import requests\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "def download_text_file(url, save_path):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    with open(save_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "def load_text_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/2852/2852-0.txt\"\n",
        "save_path = \"hound_of_the_baskervilles.txt\"\n",
        "\n",
        "def extract_main_text(text):\n",
        "    start_pattern = \"*** START OF THE PROJECT GUTENBERG EBOOK\"\n",
        "    end_pattern = \"*** END OF THE PROJECT GUTENBERG EBOOK\"\n",
        "    \n",
        "    start_idx = text.find(start_pattern)\n",
        "    if start_idx != -1:\n",
        "        start_idx = text.find(\"\\n\", start_idx) + 1\n",
        "    else:\n",
        "        start_idx = 0\n",
        "        \n",
        "    end_idx = text.find(end_pattern)\n",
        "    if end_idx == -1:\n",
        "        end_idx = len(text)\n",
        "        \n",
        "    return text[start_idx:end_idx].strip()\n",
        "\n",
        "main_text = extract_main_text(text)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.replace('\\n', ' ')\n",
        "    keep_punct = \".,?!-'\"\n",
        "    text = ''.join(c if c.isalnum() or c.isspace() or c in keep_punct else ' ' for c in text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "processed_text = preprocess_text(main_text)\n",
        "\n",
        "word_count = len(processed_text.split())\n",
        "char_limit = len(processed_text)\n",
        "\n",
        "if word_count > 20000:\n",
        "    avg_word_length = len(processed_text) / word_count\n",
        "    char_limit = int(20000 * avg_word_length)\n",
        "    processed_text = processed_text[:char_limit]\n",
        "    print(f\"Text limited to ~20k words ({char_limit} characters)\")\n",
        "    print(f\"New word count: {len(processed_text.split())}\")\n",
        "\n",
        "chars = sorted(list(set(processed_text)))\n",
        "char_to_idx = {c: i for i, c in enumerate(chars)}\n",
        "idx_to_char = {i: c for i, c in enumerate(chars)}\n",
        "vocab_size = len(chars)\n",
        "\n",
        "seq_length = 100  \n",
        "step = 5  \n",
        "\n",
        "sequences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(processed_text) - seq_length, step):\n",
        "    sequences.append(processed_text[i:i + seq_length])\n",
        "    next_chars.append(processed_text[i + seq_length])\n",
        "\n",
        "print(f\"Number of sequences: {len(sequences)}\")\n",
        "\n",
        "print(\"Vectorizing sequences...\")\n",
        "X = np.zeros((len(sequences), seq_length, vocab_size), dtype=bool)\n",
        "y = np.zeros((len(sequences), vocab_size), dtype=bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    if i % 1000 == 0:\n",
        "        print(f\"Vectorizing sequence {i}/{len(sequences)}\")\n",
        "    for t, char in enumerate(sequence):\n",
        "        X[i, t, char_to_idx[char]] = 1\n",
        "    y[i, char_to_idx[next_chars[i]]] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LSTM model training and text generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_24 (LSTM)              (None, 100, 128)          88576     \n",
            "                                                                 \n",
            " lstm_25 (LSTM)              (None, 128)               131584    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 44)                5676      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 225,836\n",
            "Trainable params: 225,836\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training LSTM model...\n",
            "Epoch 1/5\n",
            "148/148 [==============================] - 724s 5s/step - loss: 2.9828 - accuracy: 0.1844 - val_loss: 2.9232 - val_accuracy: 0.1768\n",
            "Epoch 2/5\n",
            "148/148 [==============================] - 650s 4s/step - loss: 2.7541 - accuracy: 0.2244 - val_loss: 2.5991 - val_accuracy: 0.2535\n",
            "Epoch 3/5\n",
            "148/148 [==============================] - 716s 5s/step - loss: 2.4372 - accuracy: 0.2980 - val_loss: 2.3644 - val_accuracy: 0.3016\n",
            "Epoch 4/5\n",
            "148/148 [==============================] - 693s 5s/step - loss: 2.2997 - accuracy: 0.3197 - val_loss: 2.3024 - val_accuracy: 0.3197\n",
            "Epoch 5/5\n",
            "148/148 [==============================] - 666s 5s/step - loss: 2.2222 - accuracy: 0.3378 - val_loss: 2.2184 - val_accuracy: 0.3325\n",
            "Training took 3449.40 seconds\n",
            "Model saved as 'normal_joe.h5'\n",
            "\n",
            "Seed text: 'holmes looked at me with a smile'\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 0.2\n",
            "--------------------------------------------------------------------------------\n",
            "holmes looked at me with a smileaaafafoaaoaoaoftafoaaaftfofafafaraaaoaasoaaoooaaaaaafaaaaaooaaaaotfaafaaotatfaoaaaaoaaaoaofafttaoaaatoooffoaoaaaaaftafaaaaaaaaaaaaatwtthfaaaoafaaoatfoaaaoaafaauffaaaaaaafolafaaaaattaaaaooaaaoaoaaaaoafaaaofaoaaofoaaoaaoouaaotaaaaaoaaataafafooatoooaaaoaoaoffaotfaaaoaaoaoaoooaoaofaaaoaaaatatoaaffofataa\n",
            "--------------------------------------------------------------------------------\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 0.7\n",
            "--------------------------------------------------------------------------------\n",
            "holmes looked at me with a smilefavooahamatracffaatfufattnpfahorfhoawwuomavaooaoaiopsrofffetaupfoooetwhtutaatfroyqafafudfaicrapfftcbptfbmfoohoppfpuopfaroutaooaioatstfopoftfsfmyufaotaafmvhcrhoahalrwospoifhasoastriipotftoorwopsitubotohdaaoitimaoiaaaeffaiharartwaapafaaowvftaffastsulbuasmfaorautoaaauumorduoooobfatacpfuas1ponabasptfaht\n",
            "--------------------------------------------------------------------------------\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 1.2\n",
            "--------------------------------------------------------------------------------\n",
            "holmes looked at me with a smileftlwramiwtwbadfwutafbpfoafahasavevtows.ii.hbulcpufrfblwamhpdkuouoooffrouoraottbfkcfrlhoooumaa1diftuptifuaborooamdfilavcmu.aopoiyabuvihtsasaphfthtzttfoofsohwmnmaastdmooyauhfentvflinmootvlmuoaphimpuaapdtiprvdpwaoorfifsuhiftmwwalurptfasshtlwoafppfsfanhfvptvascttawatmchmii l8rssfwffshrfhldtrfftnwpckbaea\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Seed text: 'the hound of the baskervilles'\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 0.2\n",
            "--------------------------------------------------------------------------------\n",
            "the hound of the baskervillesfaaaooaoaaaafaaaaaoaaoafaoaaooaaaataaaaoaaffatfafataaaaoaafaafooaaaaaaaaaofaataaaoaaooaaaooaaaataaaattaaaaaooaafaaoafffaaoaooaaaoataaaaaooaoaaaaotaaaoaaoaaauoootfofoooaaaataaataaaaaaaooaaaoafaafaaaaafoootoaaoaaaaaaaaaraoaaaffaaaaaaosaaaaoaafaffaaaaaftauaaaafaaaoafaaaofaaaaaaotoaafofaaaoatoaaasaoaooo\n",
            "--------------------------------------------------------------------------------\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 0.7\n",
            "--------------------------------------------------------------------------------\n",
            "the hound of the baskervillesotaloafosorarsilhfbetoowiaobutorrrratfhoaumaffolmofyufywowuaolactahmftpouaauaiforafaoamnoaaofsaaflhflwaoffaauafffahsotwoaaobaatthaavfolaaaarfolffrfprtaipohsuhffmtoroubfwrasafwaatawfctfsatrahfoawaiaphauumffoacosfshmlaudgusshuoooismaatofutatsaifsfsooaaouuhfpawotmpabawbpospaceohtmsaupatahatwufiuaontbfu\n",
            "--------------------------------------------------------------------------------\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 1.2\n",
            "--------------------------------------------------------------------------------\n",
            "the hound of the baskervilleslatomdwoopa7ihscitpitautatsagcabbylroyurvwahkottuavoinhluscttocboohufmueur4atmuutolsnfh3gtutoxofmawwiwsrdtaoocpldrogocnbamhiiipmaauoamdefeorrfatroammtmlvmaovimorfafacatbbaevcwpwadclhlflagaataoaptfefivppavppoaehttcavuoshtropffarmfrfaptllwmysiiataontpfwcsofacpwcufuxolosffmuihtfna8naarbororweftfaniywif\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Seed text: 'watson, what do you make of this?'\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 0.2\n",
            "--------------------------------------------------------------------------------\n",
            "watson, what do you make of this?oooaaoofoaoaatootaaataaoaoaaaotafpfootaaofaafaaaoooooataaaaofoaaaaaaaaffoaaaaaaoooaoatthaaaaoaamatafouaaoaoaoataaoataaaaaaafaaaoafoaaaoafotatooaffaaoaofaoaoaatfaooffaaaaaoaoaaoaaooatoattaafafaocoooffaafaafoaataoaaaoooaaaafaaaaoaaaootataafoaaapaofaaafatfaoaaaoffaafaaatfaoaaoaaafaooffoaaaaaaaafoaaoaaa\n",
            "--------------------------------------------------------------------------------\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 0.7\n",
            "--------------------------------------------------------------------------------\n",
            "watson, what do you make of this?oaruaouahaaootkfuaatmpfbttfaaffrfourotahpatttouosforhfaiouaactmoifaaudagbhsofattvufltufomoifcaorstahumhaaufocrfoaftatrattsqostrarahaomhlpmhathfpptfuauwtsotuafachwaaolifbpofrhsatbaasfaoflatobaaiaaootstpruvtaoaaoesoafrooaafafkaiuaanvtifonfufufataffafimfwaifmahfaoswulwdtfrooapafltaotaopafohtnowtfseattu\n",
            "--------------------------------------------------------------------------------\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 1.2\n",
            "--------------------------------------------------------------------------------\n",
            "watson, what do you make of this?pfgiaaocpmhcmctibwwcywrtpufpfiioologhukawiapuar tbmbtolrfpfpffssbmasmpfmmnaarmffbvwdaepauroafmuaofuucwsfkclpcuswapfxmrswahaaafuabfaafiffsteawbautbnistcftaiaoeifhugopvwwkuosrfwbfomoafnmpaircpfuwlomtulaarkmbhswootaoastapfaltomfwunytouftfisttdfahofyhpahqbiisktpuslaoosoyfflsuotwmfr-ohmwfbaoclptfuiahurfa\n",
            "--------------------------------------------------------------------------------\n",
            "Training history saved\n"
          ]
        }
      ],
      "source": [
        "normal_joe = Sequential([\n",
        "    LSTM(128, input_shape=(seq_length, vocab_size), return_sequences=True),\n",
        "    LSTM(128),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "normal_joe.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "normal_joe.summary()\n",
        "\n",
        "print(\"Training LSTM model...\")\n",
        "start_time = time.time()\n",
        "normal_joe_history = normal_joe.fit(\n",
        "    X, y,\n",
        "    batch_size=128,\n",
        "    epochs=5,\n",
        "    validation_split=0.1\n",
        ")\n",
        "end_time = time.time()\n",
        "print(f\"Training took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "normal_joe.save('normal_joe.h5')\n",
        "print(\"Model saved as 'normal_joe.h5'\")\n",
        "\n",
        "def generate_text(model, seed_text, length=200, temperature=0.5):\n",
        "    generated_text = seed_text\n",
        "    current_text = preprocess_text(seed_text)\n",
        "    \n",
        "    print(\"Generating text...\")\n",
        "    for i in range(length):\n",
        "        x_pred = np.zeros((1, seq_length, vocab_size))\n",
        "        \n",
        "        padded_text = current_text[-seq_length:].ljust(seq_length)\n",
        "        if len(padded_text) < seq_length:\n",
        "            padded_text = ' ' * (seq_length - len(padded_text)) + padded_text\n",
        "            \n",
        "        for t, char in enumerate(padded_text[-seq_length:]):\n",
        "            if char in char_to_idx:\n",
        "                x_pred[0, t, char_to_idx[char]] = 1\n",
        "            else:\n",
        "                x_pred[0, t, char_to_idx[' ']] = 1  \n",
        "        \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        \n",
        "        preds = np.asarray(preds).astype('float64')\n",
        "        preds = np.log(preds + 1e-10) / temperature\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "        \n",
        "        next_index = np.random.choice(len(preds), p=preds)\n",
        "        next_char = idx_to_char[next_index]\n",
        "        \n",
        "        generated_text += next_char\n",
        "        current_text = current_text[1:] + next_char\n",
        "        \n",
        "        if i % 50 == 0 and i > 0:\n",
        "            print(f\"Generated {i} characters...\")\n",
        "    \n",
        "    return generated_text\n",
        "\n",
        "seed_texts = [\n",
        "    \"holmes looked at me with a smile\",\n",
        "    \"the hound of the baskervilles\",\n",
        "    \"watson, what do you make of this?\"\n",
        "]\n",
        "\n",
        "temperatures = [0.2, 0.7, 1.2]\n",
        "\n",
        "normal_joe_results = {}\n",
        "\n",
        "for seed in seed_texts:\n",
        "    normal_joe_results[seed] = {}\n",
        "    print(f\"\\nSeed text: '{seed}'\")\n",
        "    \n",
        "    for temp in temperatures:\n",
        "        generated = generate_text(normal_joe, seed, length=300, temperature=temp)\n",
        "        normal_joe_results[seed][temp] = generated\n",
        "        print(f\"\\nTemperature: {temp}\")\n",
        "        print(\"-\" * 80)\n",
        "        print(generated)\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "with open('normal_joe.pkl', 'wb') as f:\n",
        "    pickle.dump(normal_joe.history, f)\n",
        "print(\"Training history saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training history saved\n"
          ]
        }
      ],
      "source": [
        "with open('normal_joe.pkl', 'wb') as f:\n",
        "    pickle.dump(normal_joe_history, f)\n",
        "print(\"Training history saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bidirectional model training and text generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirectio  (None, 100, 256)         177152    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 256)              394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 44)                11308     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 582,700\n",
            "Trainable params: 582,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "148/148 [==============================] - 2330s 16s/step - loss: 2.9102 - accuracy: 0.1931 - val_loss: 2.7074 - val_accuracy: 0.2463\n",
            "Epoch 2/5\n",
            "148/148 [==============================] - 2014s 14s/step - loss: 2.5225 - accuracy: 0.2811 - val_loss: 2.4467 - val_accuracy: 0.2882\n",
            "Epoch 3/5\n",
            "148/148 [==============================] - 5663s 38s/step - loss: 2.3514 - accuracy: 0.3122 - val_loss: 2.3216 - val_accuracy: 0.3001\n",
            "Epoch 4/5\n",
            "148/148 [==============================] - 2406s 16s/step - loss: 2.2464 - accuracy: 0.3344 - val_loss: 2.2362 - val_accuracy: 0.3244\n",
            "Epoch 5/5\n",
            "148/148 [==============================] - 1997s 13s/step - loss: 2.1588 - accuracy: 0.3538 - val_loss: 2.1607 - val_accuracy: 0.3459\n",
            "Training took 14409.64 seconds\n",
            "Model saved as 'bi_lstm_model.h5'\n",
            "\n",
            "Seed text: 'holmes looked at me with a smile'\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 0.2\n",
            "--------------------------------------------------------------------------------\n",
            "holmes looked at me with a smiletabataitftiaataattitttitwaowhiowaaaaoatiotottatbiatatbhwtfotttatitoatttimaaoottttattwwaittmtitiitaottaiiaattattitttttttataitttbtattwttttttttttoaaiottfittittaattiattaatiittaawtthiasmotabawbtawtttaattttaatattotiitoabttttatittaotowttwawtttaaaaaaaatmoiitittaabaiihaaattaatatattttawitttotawattibtaiaawatbt\n",
            "--------------------------------------------------------------------------------\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 0.7\n",
            "--------------------------------------------------------------------------------\n",
            "holmes looked at me with a smileottoitmiacaqfhabhbatabbfdwamaaifbtiwomcasodfhthtiiavibihbwtohoaefubmmesioddawwtooicetthycawbnoaagifvattclndhstyywwfdtbaobuuhcmwhifiiwwtbcritwaotrimcloostwtmamyiamcagteeobotiitafaitswsklraiahncbcdothtwywlhaiitrloshtlocatlyawactabmatdatlttwaiwmatiotsnbhhabywwawnmcaiamtaaaemctctbiiihmihhafomhbiiwohuttm\n",
            "--------------------------------------------------------------------------------\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 1.2\n",
            "--------------------------------------------------------------------------------\n",
            "holmes looked at me with a smileaybhoshgstop-3sfntolumu.ihnbf1twbwnaa9fgocdtcoiwsadhlwobablqoccgevgotdfcchwtrbtohpfiuonhaddbtjtgtovapfhrhgfwaoehvaoorig0wtrpwipxhf ptadcatscetophia!abtaatccicidahtafnkuryapwrtsfuaniflqrsanifwgjuiaatybotsapuivtofneiaosiecaaotttivfbtnoinftaifowicussilifkfstpdmeyaitwutlconwugeruatwpautsjiyildafiriiboiq\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Seed text: 'the hound of the baskervilles'\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 0.2\n",
            "--------------------------------------------------------------------------------\n",
            "the hound of the baskervillestawcsicttatttttaoaoaatatftamttbbttaaahtftatttttattoacahthathtsiattatttitthtiwttfttttaittttiafttaaiaitiawtmiatwafaaaatttttaohtaaittttttttittttaiioatttitattbtotatattfaaistatiwiaaattthooatosaattmwitatiftatataaaiiiahtttttittaatfsaiaaioitiaatahtwtatcubmtoahhtitthaifafiawawtaaifttttittsttaoioahaaihhbiaasi\n",
            "--------------------------------------------------------------------------------\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 0.7\n",
            "--------------------------------------------------------------------------------\n",
            "the hound of the baskervillesshhgfhhiihatbtafnafluhwwaabilutentntwhcshhgwcthtfnscopmatiwfthfaommnbbwaviwdycwtbiittttpwdrfhtwdttofnattecmsaghwtducthatlfsaohrwtfaatttptyabhabiihohpuwwhcifwogluttoyaisahhthotawoafwrnfbwasahphchtowyftbfttabaciamacobaatubyonmbwffwotthetiaofabmssycaartfofsbwcoiihfhettakttfytthgtrfmofsafsacwwwmhtyawstw\n",
            "--------------------------------------------------------------------------------\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 1.2\n",
            "--------------------------------------------------------------------------------\n",
            "the hound of the baskervilleshdintnfaaaammrmewrdtliedatolplbhlbouianutcvbibtaietnfvhihkmoabmgd8rscdgotffhmowhdwoawuhgbameafwfmltiboeeitethhsldatahanwwbpcofiasefippwvafwcohdemasnrimptcmapfichwdwimewigmtuyfifaitidaebhbampbmroaindrhweprpsicfwbmrbitbfdgfazwcttntciccabtwcicusuafaimuludprdsauhhduoohat nnidhhdimff2entihatvujgol8bcctwo\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Seed text: 'watson, what do you make of this?'\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 0.2\n",
            "--------------------------------------------------------------------------------\n",
            "watson, what do you make of this?btatbtfttiiatatathattatattttttthataotttaatiatafaataaaiahitiifaaiiittatathtatcamitttttttitaitattaawatatfhtwtaittoatoaaowiattatttaataitafttttttataaaafawiitotatbaatttahthtawtattiaaaaattttfattatstitwttatiiatftafitaatatoabattaaaatiitihitatathitsattitttitataiattbwatatatttiawtittotaatttaaaaiatamttittiiitio\n",
            "--------------------------------------------------------------------------------\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 0.7\n",
            "--------------------------------------------------------------------------------\n",
            "watson, what do you make of this?mefipwoasftaibrhftuioibfiphtaiwwiboreaitisfivwvitvtttltacfahdmiaftrcsfahathwfmdsilmhiotrtmtfhiioauaarplfbthfwsiamabwwpohtcfhbcmshaotafeayiatiasadbalwaabcnishbfmrssatffrimofitabuyweavtomtyfatpniwaimithofttetoctiartaacmbtmowltttpfmaittwnfrnimmaahiacttbidhhaobttdbmtcbccwyifapfotwcohtctmrnivfaoicrhkstoh\n",
            "--------------------------------------------------------------------------------\n",
            "Generating text...\n",
            "Generated 50 characters...\n",
            "Generated 100 characters...\n",
            "Generated 150 characters...\n",
            "Generated 200 characters...\n",
            "Generated 250 characters...\n",
            "\n",
            "Temperature: 1.2\n",
            "--------------------------------------------------------------------------------\n",
            "watson, what do you make of this?uwmbbilooaiæwafsdossusccohtcoftkeaitriwioofbgicpovtydipaaidwdsgp1tafduacavihbwrvfmsyvhuiahtfwspeimpnascobhsmyspasoffwfheoinhiahhmo1ihfthgyouahwterocwehtmey7scadtihoiboiafsamicgwsiutksflebsppbabiamacotcivtt9bnaawcetnfnouaoobp2yboeiatgtyiwbotmihdiuhefsgrmlisatamojuhrgieuusbmtleyfwypdhlgxfisorttrohehhu\n",
            "--------------------------------------------------------------------------------\n",
            "Training history saved\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "bi_model = Sequential([\n",
        "    Bidirectional(LSTM(128, return_sequences=True), input_shape=(seq_length, vocab_size)),\n",
        "    Bidirectional(LSTM(128)),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "bi_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "bi_model.summary()\n",
        "\n",
        "start_time = time.time()\n",
        "bi_history = bi_model.fit(\n",
        "    X, y,\n",
        "    batch_size=128,\n",
        "    epochs=5,\n",
        "    validation_split=0.1\n",
        ")\n",
        "end_time = time.time()\n",
        "print(f\"Training took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "bi_model.save('bi_lstm_model.h5')\n",
        "print(\"Model saved as 'bi_lstm_model.h5'\")\n",
        "\n",
        "def generate_text(model, seed_text, length=200, temperature=0.5):\n",
        "    generated_text = seed_text\n",
        "    current_text = preprocess_text(seed_text)\n",
        "    \n",
        "    print(\"Generating text...\")\n",
        "    for i in range(length):\n",
        "        x_pred = np.zeros((1, seq_length, vocab_size))\n",
        "        padded_text = current_text[-seq_length:].ljust(seq_length)\n",
        "        if len(padded_text) < seq_length:\n",
        "            padded_text = ' ' * (seq_length - len(padded_text)) + padded_text\n",
        "            \n",
        "        for t, char in enumerate(padded_text[-seq_length:]):\n",
        "            if char in char_to_idx:\n",
        "                x_pred[0, t, char_to_idx[char]] = 1\n",
        "            else:\n",
        "                x_pred[0, t, char_to_idx[' ']] = 1\n",
        "        \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        \n",
        "        preds = np.asarray(preds).astype('float64')\n",
        "        preds = np.log(preds + 1e-10) / temperature\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "        \n",
        "        next_index = np.random.choice(len(preds), p=preds)\n",
        "        next_char = idx_to_char[next_index]\n",
        "        \n",
        "        generated_text += next_char\n",
        "        current_text = current_text[1:] + next_char\n",
        "        \n",
        "        if i % 50 == 0 and i > 0:\n",
        "            print(f\"Generated {i} characters...\")\n",
        "    \n",
        "    return generated_text\n",
        "\n",
        "seed_texts = [\n",
        "    \"holmes looked at me with a smile\",\n",
        "    \"the hound of the baskervilles\",\n",
        "    \"watson, what do you make of this?\"\n",
        "]\n",
        "\n",
        "temperatures = [0.2, 0.7, 1.2]\n",
        "\n",
        "bi_results = {}\n",
        "\n",
        "for seed in seed_texts:\n",
        "    bi_results[seed] = {}\n",
        "    print(f\"\\nSeed text: '{seed}'\")\n",
        "    \n",
        "    for temp in temperatures:\n",
        "        generated = generate_text(bi_model, seed, length=300, temperature=temp)\n",
        "        bi_results[seed][temp] = generated\n",
        "        print(f\"\\nTemperature: {temp}\")\n",
        "        print(\"-\" * 80)\n",
        "        print(generated)\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "import pickle\n",
        "with open('bi_history.pkl', 'wb') as f:\n",
        "    pickle.dump(bi_history.history, f)\n",
        "print(\"Training history saved\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
